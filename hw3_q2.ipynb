{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "geographic-treasure",
   "metadata": {},
   "source": [
    "# 2. For the PCY algorithm, create up to 5 compact hash tables. What is the difference in results and time of execution for 1,2,3,4 and 5 tables? Comment your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "north-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def readdata(k, fname=\"groceries.csv\", report=False):\n",
    "    C_k = []\n",
    "    b = 0\n",
    "    \n",
    "    with open(\"groceries.csv\", \"rt\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n', '')  # remove newline symbol\n",
    "\n",
    "            if line != \"\":\n",
    "                # gather all items in one basket\n",
    "                C_k.append(line)                 \n",
    "            else: \n",
    "                # end of basket, report all itemsets\n",
    "                for itemset in itertools.combinations(C_k, k):\n",
    "                    yield frozenset(itemset)\n",
    "                C_k = []\n",
    "                \n",
    "                # report progress\n",
    "                # print every 1000th element to reduce clutter\n",
    "                if report:\n",
    "                    if b % 1000 == 0:  \n",
    "                        print('processing bin ', b)\n",
    "                    b += 1\n",
    "\n",
    "    # last basket\n",
    "    if len(C_k) > 0:\n",
    "        for itemset in itertools.combinations(C_k, k):\n",
    "            yield frozenset(itemset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handed-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "N=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "scientific-wilson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7011 items\n"
     ]
    }
   ],
   "source": [
    "# find frequent 1-tuples (individual items)\n",
    "C1 = {}\n",
    "for key in readdata(k=1, report=False):\n",
    "    if key not in C1:\n",
    "        C1[key] = 1\n",
    "    else:\n",
    "        C1[key] += 1    \n",
    "        \n",
    "print(\"{} items\".format(len(C1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demanding-musical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 items with >50 occurances\n"
     ]
    }
   ],
   "source": [
    "# filter stage\n",
    "L1 = {}\n",
    "for key, count in C1.items():\n",
    "    if count >= N:\n",
    "        L1[key] = count\n",
    "print('{} items with >{} occurances'.format(len(L1), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advisory-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "C2_items = set([a.union(b) for a in L1.keys() for b in L1.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enabling-sampling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(C2_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-peninsula",
   "metadata": {},
   "source": [
    "## 1-table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "female-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_table1 = time.time()\n",
    "# hash table\n",
    "max_hash1_table1 = 5*1000000-673\n",
    "\n",
    "H1_table1 = np.zeros((max_hash1_table1,), dtype=np.int)\n",
    "\n",
    "for key in readdata(k=2, report=True):\n",
    "    hash_cell_1_table1 = hash(key) % max_hash1_table1\n",
    "    H1_table1[hash_cell_1_table1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "junior-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact hash table\n",
    "H_good_1_table1 = set(np.where(H1_table1 >= N)[0])\n",
    "\n",
    "del H1_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comprehensive-orchestra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items\n"
     ]
    }
   ],
   "source": [
    "# find frequent 2-tuples\n",
    "C2_table1 = {}\n",
    "for key in readdata(k=2):\n",
    "    # hash-based filtering stage from PCY\n",
    "    hash_cell_1_table1 = hash(key) % max_hash1_table1\n",
    "    if hash_cell_1_table1 not in H_good_1_table1:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # filter out non-frequent tuples\n",
    "    if key not in C2_items:\n",
    "        continue\n",
    "\n",
    "    # record frequent tuples\n",
    "    if key not in C2_table1:\n",
    "        C2_table1[key] = 1\n",
    "    else:\n",
    "        C2_table1[key] += 1\n",
    "        \n",
    "print(\"{} items\".format(len(C2_table1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "danish-header",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items with >50 occurances\n"
     ]
    }
   ],
   "source": [
    "# filter stage\n",
    "L2_table1 = {}\n",
    "for key, count in C2_table1.items():\n",
    "    if count >= N:\n",
    "        L2_table1[key] = count\n",
    "print('{} items with >{} occurances'.format(len(L2_table1), N))\n",
    "end_time_table1=time.time()\n",
    "table1_time=end_time_table1-start_time_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-organ",
   "metadata": {},
   "source": [
    "### Generate rules A -> B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "indie-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: whole milk --> rolls/buns with interest 108.960364\n",
      "2: whole milk --> other vegetables with interest 61.977455\n",
      "3: whole milk --> canned beer with interest 259.905455\n",
      "4: whole milk --> bottled water with interest 66.975636\n",
      "5: whole milk --> soda with interest 155.943273\n",
      "6: newspapers --> whole milk with interest 120.956000\n",
      "7: whole milk --> bottled beer with interest 119.956364\n",
      "8: other vegetables --> rolls/buns with interest 108.960364\n",
      "9: canned beer --> rolls/buns with interest 108.960364\n",
      "10: bottled water --> rolls/buns with interest 108.960364\n",
      "11: soda --> rolls/buns with interest 108.960364\n",
      "12: newspapers --> rolls/buns with interest 108.960364\n",
      "13: bottled beer --> rolls/buns with interest 108.960364\n",
      "14: other vegetables --> canned beer with interest 259.905455\n",
      "15: bottled water --> other vegetables with interest 61.977455\n",
      "16: other vegetables --> soda with interest 155.943273\n",
      "17: newspapers --> other vegetables with interest 61.977455\n",
      "18: other vegetables --> bottled beer with interest 119.956364\n",
      "19: bottled water --> canned beer with interest 259.905455\n",
      "20: soda --> canned beer with interest 259.905455\n",
      "21: newspapers --> canned beer with interest 259.905455\n",
      "22: bottled beer --> canned beer with interest 259.905455\n",
      "23: bottled water --> soda with interest 155.943273\n",
      "24: newspapers --> bottled water with interest 66.975636\n",
      "25: bottled water --> bottled beer with interest 119.956364\n",
      "26: newspapers --> soda with interest 155.943273\n",
      "27: bottled beer --> soda with interest 155.943273\n",
      "28: newspapers --> bottled beer with interest 119.956364\n"
     ]
    }
   ],
   "source": [
    "L2_table1 = [ elem for elem in list(L2_table1) if len(elem)>1] # clean our list a bit. \n",
    "count=1\n",
    "for i in range(len(L2_table1)):\n",
    "\n",
    "    A, B = list(L2_table1[i])\n",
    "    support_AB = C2_table1[frozenset([A, B])]\n",
    "    support_A = C1[frozenset([A])]\n",
    "    conf_A_leads_to_B = support_AB / support_A\n",
    "    \n",
    "    support_B = C1[frozenset([B])]\n",
    "    prob_B = support_B / 2750.0\n",
    "    \n",
    "    interest_A_leads_to_B = conf_A_leads_to_B - prob_B\n",
    "    if interest_A_leads_to_B > 0.7:\n",
    "        print(\"{}: {} --> {} with interest {:3f}\".format(count,A, B, interest_A_leads_to_B))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-hampshire",
   "metadata": {},
   "source": [
    "## 2-table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "robust-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_table2 = time.time()\n",
    "# hash table\n",
    "max_hash1_table2 = 5*1000000-673\n",
    "max_hash2_table2 = 5*1000000+673\n",
    "\n",
    "H1_table2 = np.zeros((max_hash1_table2,), dtype=np.int)\n",
    "H2_table2 = np.zeros((max_hash2_table2,), dtype=np.int)\n",
    "for key in readdata(k=2, report=True):\n",
    "    hash_cell_1_table2 = hash(key) % max_hash1_table2\n",
    "    H1_table2[hash_cell_1_table2] += 1\n",
    "    hash_cell_2_table2 = hash(key) % max_hash2_table2\n",
    "    H2_table2[hash_cell_2_table2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caroline-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact hash table\n",
    "H_good_1_table2 = set(np.where(H1_table2 >= N)[0])\n",
    "H_good_2_table2 = set(np.where(H2_table2 >= N)[0])\n",
    "\n",
    "del H1_table2\n",
    "del H2_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excited-jersey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items\n"
     ]
    }
   ],
   "source": [
    "# find frequent 2-tuples\n",
    "C2_table2 = {}\n",
    "for key in readdata(k=2):\n",
    "    # hash-based filtering stage from PCY\n",
    "    hash_cell_1_table2 = hash(key) % max_hash1_table2\n",
    "    if hash_cell_1_table2 not in H_good_1_table2:\n",
    "        continue\n",
    "\n",
    "    hash_cell_2_table2 = hash(key) % max_hash2_table2\n",
    "    if hash_cell_2_table2 not in H_good_2_table2:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # filter out non-frequent tuples\n",
    "    if key not in C2_items:\n",
    "        continue\n",
    "\n",
    "    # record frequent tuples\n",
    "    if key not in C2_table2:\n",
    "        C2_table2[key] = 1\n",
    "    else:\n",
    "        C2_table2[key] += 1\n",
    "        \n",
    "print(\"{} items\".format(len(C2_table2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proud-floor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items with >50 occurances\n"
     ]
    }
   ],
   "source": [
    "# filter stage\n",
    "L2_table2 = {}\n",
    "for key, count in C2_table2.items():\n",
    "    if count >= N:\n",
    "        L2_table2[key] = count\n",
    "print('{} items with >{} occurances'.format(len(L2_table2), N))\n",
    "end_time_table2=time.time()\n",
    "table2_time=end_time_table2-start_time_table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-lithuania",
   "metadata": {},
   "source": [
    "###  Generate rules A -> B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "latter-rebound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: whole milk --> rolls/buns with interest 108.960364\n",
      "2: whole milk --> other vegetables with interest 61.977455\n",
      "3: whole milk --> canned beer with interest 259.905455\n",
      "4: whole milk --> bottled water with interest 66.975636\n",
      "5: whole milk --> soda with interest 155.943273\n",
      "6: newspapers --> whole milk with interest 120.956000\n",
      "7: whole milk --> bottled beer with interest 119.956364\n",
      "8: other vegetables --> rolls/buns with interest 108.960364\n",
      "9: canned beer --> rolls/buns with interest 108.960364\n",
      "10: bottled water --> rolls/buns with interest 108.960364\n",
      "11: soda --> rolls/buns with interest 108.960364\n",
      "12: newspapers --> rolls/buns with interest 108.960364\n",
      "13: bottled beer --> rolls/buns with interest 108.960364\n",
      "14: other vegetables --> canned beer with interest 259.905455\n",
      "15: bottled water --> other vegetables with interest 61.977455\n",
      "16: other vegetables --> soda with interest 155.943273\n",
      "17: newspapers --> other vegetables with interest 61.977455\n",
      "18: other vegetables --> bottled beer with interest 119.956364\n",
      "19: bottled water --> canned beer with interest 259.905455\n",
      "20: soda --> canned beer with interest 259.905455\n",
      "21: newspapers --> canned beer with interest 259.905455\n",
      "22: bottled beer --> canned beer with interest 259.905455\n",
      "23: bottled water --> soda with interest 155.943273\n",
      "24: newspapers --> bottled water with interest 66.975636\n",
      "25: bottled water --> bottled beer with interest 119.956364\n",
      "26: newspapers --> soda with interest 155.943273\n",
      "27: bottled beer --> soda with interest 155.943273\n",
      "28: newspapers --> bottled beer with interest 119.956364\n"
     ]
    }
   ],
   "source": [
    "L2_table2 = [ elem for elem in list(L2_table2) if len(elem)>1] # clean our list a bit. \n",
    "count=1\n",
    "for i in range(len(L2_table2)):\n",
    "\n",
    "    A, B = list(L2_table2[i])\n",
    "    support_AB = C2_table2[frozenset([A, B])]\n",
    "    support_A = C1[frozenset([A])]\n",
    "    conf_A_leads_to_B = support_AB / support_A\n",
    "    \n",
    "    support_B = C1[frozenset([B])]\n",
    "    prob_B = support_B / 2750.0\n",
    "    \n",
    "    interest_A_leads_to_B = conf_A_leads_to_B - prob_B\n",
    "    \n",
    "    if interest_A_leads_to_B > 0.7:\n",
    "        print(\"{}: {} --> {} with interest {:3f}\".format(count,A, B, interest_A_leads_to_B))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-afghanistan",
   "metadata": {},
   "source": [
    "## 3-table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surprising-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_table3 = time.time()\n",
    "# hash table\n",
    "max_hash1_table3 = 5*1000000-673\n",
    "max_hash2_table3 = 5*1000000+673\n",
    "max_hash3_table3 = 5*1000000+673\n",
    "\n",
    "H1_table3 = np.zeros((max_hash1_table3,), dtype=np.int)\n",
    "H2_table3 = np.zeros((max_hash2_table3,), dtype=np.int)\n",
    "H3_table3 = np.zeros((max_hash3_table3,), dtype=np.int)\n",
    "\n",
    "for key in readdata(k=2, report=True):\n",
    "    hash_cell_1_table3 = hash(key) % max_hash1_table3\n",
    "    H1_table3[hash_cell_1_table3] += 1\n",
    "    hash_cell_2_table3 = hash(key) % max_hash2_table3\n",
    "    H2_table3[hash_cell_2_table3] += 1\n",
    "    hash_cell_3_table3 = hash(key) % max_hash3_table3\n",
    "    H3_table3[hash_cell_3_table3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incident-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact hash table\n",
    "H_good_1_table3 = set(np.where(H1_table3 >= N)[0])\n",
    "H_good_2_table3 = set(np.where(H2_table3 >= N)[0])\n",
    "H_good_3_table3 = set(np.where(H3_table3 >= N)[0])\n",
    "\n",
    "del H1_table3\n",
    "del H2_table3\n",
    "del H3_table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "proud-crystal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items\n"
     ]
    }
   ],
   "source": [
    "# find frequent 2-tuples\n",
    "C2_table3 = {}\n",
    "for key in readdata(k=2):\n",
    "    # hash-based filtering stage from PCY\n",
    "    hash_cell_1_table3 = hash(key) % max_hash1_table3\n",
    "    if hash_cell_1_table3 not in H_good_1_table3:\n",
    "        continue\n",
    "\n",
    "    hash_cell_2_table3 = hash(key) % max_hash2_table3\n",
    "    if hash_cell_2_table3 not in H_good_2_table3:\n",
    "        continue\n",
    "        \n",
    "    hash_cell_3_table3 = hash(key) % max_hash3_table3\n",
    "    if hash_cell_3_table3 not in H_good_3_table3:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # filter out non-frequent tuples\n",
    "    if key not in C2_items:\n",
    "        continue\n",
    "\n",
    "    # record frequent tuples\n",
    "    if key not in C2_table3:\n",
    "        C2_table3[key] = 1\n",
    "    else:\n",
    "        C2_table3[key] += 1\n",
    "        \n",
    "print(\"{} items\".format(len(C2_table3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "contemporary-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items with >50 occurances\n"
     ]
    }
   ],
   "source": [
    "# filter stage\n",
    "L2_table3 = {}\n",
    "for key, count in C2_table3.items():\n",
    "    if count >= N:\n",
    "        L2_table3[key] = count\n",
    "print('{} items with >{} occurances'.format(len(L2_table3), N))\n",
    "end_time_table3=time.time()\n",
    "table3_time=end_time_table3-start_time_table3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-jackson",
   "metadata": {},
   "source": [
    "### Generate rules A -> B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deadly-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: whole milk --> rolls/buns with interest 108.960364\n",
      "2: whole milk --> other vegetables with interest 61.977455\n",
      "3: whole milk --> canned beer with interest 259.905455\n",
      "4: whole milk --> bottled water with interest 66.975636\n",
      "5: whole milk --> soda with interest 155.943273\n",
      "6: newspapers --> whole milk with interest 120.956000\n",
      "7: whole milk --> bottled beer with interest 119.956364\n",
      "8: other vegetables --> rolls/buns with interest 108.960364\n",
      "9: canned beer --> rolls/buns with interest 108.960364\n",
      "10: bottled water --> rolls/buns with interest 108.960364\n",
      "11: soda --> rolls/buns with interest 108.960364\n",
      "12: newspapers --> rolls/buns with interest 108.960364\n",
      "13: bottled beer --> rolls/buns with interest 108.960364\n",
      "14: other vegetables --> canned beer with interest 259.905455\n",
      "15: bottled water --> other vegetables with interest 61.977455\n",
      "16: other vegetables --> soda with interest 155.943273\n",
      "17: newspapers --> other vegetables with interest 61.977455\n",
      "18: other vegetables --> bottled beer with interest 119.956364\n",
      "19: bottled water --> canned beer with interest 259.905455\n",
      "20: soda --> canned beer with interest 259.905455\n",
      "21: newspapers --> canned beer with interest 259.905455\n",
      "22: bottled beer --> canned beer with interest 259.905455\n",
      "23: bottled water --> soda with interest 155.943273\n",
      "24: newspapers --> bottled water with interest 66.975636\n",
      "25: bottled water --> bottled beer with interest 119.956364\n",
      "26: newspapers --> soda with interest 155.943273\n",
      "27: bottled beer --> soda with interest 155.943273\n",
      "28: newspapers --> bottled beer with interest 119.956364\n"
     ]
    }
   ],
   "source": [
    "L2_table3 = [ elem for elem in list(L2_table3) if len(elem)>1] # clean our list a bit. \n",
    "count=1\n",
    "for i in range(len(L2_table3)):\n",
    "\n",
    "    A, B = list(L2_table3[i])\n",
    "    support_AB = C2_table3[frozenset([A, B])]\n",
    "    support_A = C1[frozenset([A])]\n",
    "    conf_A_leads_to_B = support_AB / support_A\n",
    "    \n",
    "    support_B = C1[frozenset([B])]\n",
    "    prob_B = support_B / 2750.0\n",
    "    \n",
    "    interest_A_leads_to_B = conf_A_leads_to_B - prob_B\n",
    "    \n",
    "    if interest_A_leads_to_B > 0.7:\n",
    "        print(\"{}: {} --> {} with interest {:3f}\".format(count,A, B, interest_A_leads_to_B))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-marble",
   "metadata": {},
   "source": [
    "## 4-table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "consecutive-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_table4 = time.time()\n",
    "# hash table\n",
    "max_hash1_table4 = 5*1000000-673\n",
    "max_hash2_table4 = 5*1000000+673\n",
    "max_hash3_table4 = 5*1000000+673\n",
    "max_hash4_table4 = 5*1000000+673\n",
    "\n",
    "H1_table4 = np.zeros((max_hash1_table4,), dtype=np.int)\n",
    "H2_table4 = np.zeros((max_hash2_table4,), dtype=np.int)\n",
    "H3_table4 = np.zeros((max_hash3_table4,), dtype=np.int)\n",
    "H4_table4 = np.zeros((max_hash4_table4,), dtype=np.int)\n",
    "\n",
    "for key in readdata(k=2, report=True):\n",
    "    hash_cell_1_table4 = hash(key) % max_hash1_table4\n",
    "    H1_table4[hash_cell_1_table4] += 1\n",
    "    hash_cell_2_table4 = hash(key) % max_hash2_table4\n",
    "    H2_table4[hash_cell_2_table4] += 1\n",
    "    hash_cell_3_table4 = hash(key) % max_hash3_table4\n",
    "    H3_table4[hash_cell_3_table4] += 1\n",
    "    hash_cell_4_table4 = hash(key) % max_hash4_table4\n",
    "    H4_table4[hash_cell_4_table4] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "apparent-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact hash table\n",
    "H_good_1_table4 = set(np.where(H1_table4 >= N)[0])\n",
    "H_good_2_table4 = set(np.where(H2_table4 >= N)[0])\n",
    "H_good_3_table4 = set(np.where(H3_table4 >= N)[0])\n",
    "H_good_4_table4 = set(np.where(H4_table4 >= N)[0])\n",
    "\n",
    "del H1_table4\n",
    "del H2_table4\n",
    "del H3_table4\n",
    "del H4_table4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "growing-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items\n"
     ]
    }
   ],
   "source": [
    "# find frequent 2-tuples\n",
    "C2_table4 = {}\n",
    "for key in readdata(k=2):\n",
    "    # hash-based filtering stage from PCY\n",
    "    hash_cell_1_table4 = hash(key) % max_hash1_table4\n",
    "    if hash_cell_1_table4 not in H_good_1_table4:\n",
    "        continue\n",
    "\n",
    "    hash_cell_2_table4 = hash(key) % max_hash2_table4\n",
    "    if hash_cell_2_table4 not in H_good_2_table4:\n",
    "        continue\n",
    "        \n",
    "    hash_cell_3_table4 = hash(key) % max_hash3_table4\n",
    "    if hash_cell_3_table4 not in H_good_3_table4:\n",
    "        continue\n",
    "    hash_cell_4_table4 = hash(key) % max_hash4_table4\n",
    "    if hash_cell_4_table4 not in H_good_4_table4:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # filter out non-frequent tuples\n",
    "    if key not in C2_items:\n",
    "        continue\n",
    "\n",
    "    # record frequent tuples\n",
    "    if key not in C2_table4:\n",
    "        C2_table4[key] = 1\n",
    "    else:\n",
    "        C2_table4[key] += 1\n",
    "        \n",
    "print(\"{} items\".format(len(C2_table4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "suffering-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items with >50 occurances\n"
     ]
    }
   ],
   "source": [
    "# filter stage\n",
    "L2_table4 = {}\n",
    "for key, count in C2_table4.items():\n",
    "    if count >= N:\n",
    "        L2_table4[key] = count\n",
    "print('{} items with >{} occurances'.format(len(L2_table4), N))\n",
    "end_time_table4=time.time()\n",
    "table4_time=end_time_table4-start_time_table4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-cologne",
   "metadata": {},
   "source": [
    "### Generate rules A -> B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "arranged-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: whole milk --> rolls/buns with interest 108.960364\n",
      "2: whole milk --> other vegetables with interest 61.977455\n",
      "3: whole milk --> canned beer with interest 259.905455\n",
      "4: whole milk --> bottled water with interest 66.975636\n",
      "5: whole milk --> soda with interest 155.943273\n",
      "6: newspapers --> whole milk with interest 120.956000\n",
      "7: whole milk --> bottled beer with interest 119.956364\n",
      "8: other vegetables --> rolls/buns with interest 108.960364\n",
      "9: canned beer --> rolls/buns with interest 108.960364\n",
      "10: bottled water --> rolls/buns with interest 108.960364\n",
      "11: soda --> rolls/buns with interest 108.960364\n",
      "12: newspapers --> rolls/buns with interest 108.960364\n",
      "13: bottled beer --> rolls/buns with interest 108.960364\n",
      "14: other vegetables --> canned beer with interest 259.905455\n",
      "15: bottled water --> other vegetables with interest 61.977455\n",
      "16: other vegetables --> soda with interest 155.943273\n",
      "17: newspapers --> other vegetables with interest 61.977455\n",
      "18: other vegetables --> bottled beer with interest 119.956364\n",
      "19: bottled water --> canned beer with interest 259.905455\n",
      "20: soda --> canned beer with interest 259.905455\n",
      "21: newspapers --> canned beer with interest 259.905455\n",
      "22: bottled beer --> canned beer with interest 259.905455\n",
      "23: bottled water --> soda with interest 155.943273\n",
      "24: newspapers --> bottled water with interest 66.975636\n",
      "25: bottled water --> bottled beer with interest 119.956364\n",
      "26: newspapers --> soda with interest 155.943273\n",
      "27: bottled beer --> soda with interest 155.943273\n",
      "28: newspapers --> bottled beer with interest 119.956364\n"
     ]
    }
   ],
   "source": [
    "L2_table4 = [ elem for elem in list(L2_table4) if len(elem)>1] # clean our list a bit. \n",
    "count=1\n",
    "for i in range(len(L2_table4)):\n",
    "\n",
    "    A, B = list(L2_table4[i])\n",
    "    support_AB = C2_table4[frozenset([A, B])]\n",
    "    support_A = C1[frozenset([A])]\n",
    "    conf_A_leads_to_B = support_AB / support_A\n",
    "    \n",
    "    support_B = C1[frozenset([B])]\n",
    "    prob_B = support_B / 2750.0\n",
    "    \n",
    "    interest_A_leads_to_B = conf_A_leads_to_B - prob_B\n",
    "    \n",
    "    if interest_A_leads_to_B > 0.7:\n",
    "        print(\"{}: {} --> {} with interest {:3f}\".format(count,A, B, interest_A_leads_to_B))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-monroe",
   "metadata": {},
   "source": [
    "## 5-table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "athletic-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_table5 = time.time()\n",
    "# hash table\n",
    "max_hash1_table5 = 5*1000000-673\n",
    "max_hash2_table5 = 5*1000000+673\n",
    "max_hash3_table5 = 5*1000000+673\n",
    "max_hash4_table5 = 5*1000000+673\n",
    "max_hash5_table5 = 5*1000000+673\n",
    "\n",
    "H1_table5 = np.zeros((max_hash1_table5,), dtype=np.int)\n",
    "H2_table5 = np.zeros((max_hash2_table5,), dtype=np.int)\n",
    "H3_table5 = np.zeros((max_hash3_table5,), dtype=np.int)\n",
    "H4_table5 = np.zeros((max_hash4_table5,), dtype=np.int)\n",
    "H5_table5 = np.zeros((max_hash5_table5,), dtype=np.int)\n",
    "\n",
    "for key in readdata(k=2, report=True):\n",
    "    hash_cell_1_table5 = hash(key) % max_hash1_table5\n",
    "    H1_table5[hash_cell_1_table5] += 1\n",
    "    hash_cell_2_table5 = hash(key) % max_hash2_table5\n",
    "    H2_table5[hash_cell_2_table5] += 1\n",
    "    hash_cell_3_table5 = hash(key) % max_hash3_table5\n",
    "    H3_table5[hash_cell_3_table5] += 1\n",
    "    hash_cell_4_table5 = hash(key) % max_hash4_table5\n",
    "    H4_table5[hash_cell_4_table5] += 1\n",
    "    hash_cell_5_table5 = hash(key) % max_hash5_table5\n",
    "    H5_table5[hash_cell_5_table5] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pending-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact hash table\n",
    "H_good_1_table5 = set(np.where(H1_table5 >= N)[0])\n",
    "H_good_2_table5 = set(np.where(H2_table5 >= N)[0])\n",
    "H_good_3_table5 = set(np.where(H3_table5 >= N)[0])\n",
    "H_good_4_table5 = set(np.where(H4_table5 >= N)[0])\n",
    "H_good_5_table5 = set(np.where(H5_table5 >= N)[0])\n",
    "\n",
    "del H1_table5\n",
    "del H2_table5\n",
    "del H3_table5\n",
    "del H4_table5\n",
    "del H5_table5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "passing-privacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items\n"
     ]
    }
   ],
   "source": [
    "# find frequent 2-tuples\n",
    "C2_table5 = {}\n",
    "for key in readdata(k=2):\n",
    "    # hash-based filtering stage from PCY\n",
    "    hash_cell_1_table5 = hash(key) % max_hash1_table5\n",
    "    if hash_cell_1_table5 not in H_good_1_table5:\n",
    "        continue\n",
    "\n",
    "    hash_cell_2_table5 = hash(key) % max_hash2_table5\n",
    "    if hash_cell_2_table5 not in H_good_2_table5:\n",
    "        continue\n",
    "        \n",
    "    hash_cell_3_table5 = hash(key) % max_hash3_table5\n",
    "    if hash_cell_3_table5 not in H_good_3_table5:\n",
    "        continue\n",
    "    hash_cell_4_table5 = hash(key) % max_hash4_table5\n",
    "    if hash_cell_4_table5 not in H_good_4_table5:\n",
    "        continue\n",
    "    hash_cell_5_table5 = hash(key) % max_hash5_table5\n",
    "    if hash_cell_5_table5 not in H_good_5_table5:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # filter out non-frequent tuples\n",
    "    if key not in C2_items:\n",
    "        continue\n",
    "\n",
    "    # record frequent tuples\n",
    "    if key not in C2_table5:\n",
    "        C2_table5[key] = 1\n",
    "    else:\n",
    "        C2_table5[key] += 1\n",
    "        \n",
    "print(\"{} items\".format(len(C2_table5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "superb-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 items with >50 occurances\n"
     ]
    }
   ],
   "source": [
    "# filter stage\n",
    "L2_table5 = {}\n",
    "for key, count in C2_table5.items():\n",
    "    if count >= N:\n",
    "        L2_table5[key] = count\n",
    "print('{} items with >{} occurances'.format(len(L2_table5), N))\n",
    "end_time_table5=time.time()\n",
    "table5_time=end_time_table5-start_time_table5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-royalty",
   "metadata": {},
   "source": [
    "### Generate rules A -> B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "second-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: whole milk --> rolls/buns with interest 108.960364\n",
      "2: whole milk --> other vegetables with interest 61.977455\n",
      "3: whole milk --> canned beer with interest 259.905455\n",
      "4: whole milk --> bottled water with interest 66.975636\n",
      "5: whole milk --> soda with interest 155.943273\n",
      "6: newspapers --> whole milk with interest 120.956000\n",
      "7: whole milk --> bottled beer with interest 119.956364\n",
      "8: other vegetables --> rolls/buns with interest 108.960364\n",
      "9: canned beer --> rolls/buns with interest 108.960364\n",
      "10: bottled water --> rolls/buns with interest 108.960364\n",
      "11: soda --> rolls/buns with interest 108.960364\n",
      "12: newspapers --> rolls/buns with interest 108.960364\n",
      "13: bottled beer --> rolls/buns with interest 108.960364\n",
      "14: other vegetables --> canned beer with interest 259.905455\n",
      "15: bottled water --> other vegetables with interest 61.977455\n",
      "16: other vegetables --> soda with interest 155.943273\n",
      "17: newspapers --> other vegetables with interest 61.977455\n",
      "18: other vegetables --> bottled beer with interest 119.956364\n",
      "19: bottled water --> canned beer with interest 259.905455\n",
      "20: soda --> canned beer with interest 259.905455\n",
      "21: newspapers --> canned beer with interest 259.905455\n",
      "22: bottled beer --> canned beer with interest 259.905455\n",
      "23: bottled water --> soda with interest 155.943273\n",
      "24: newspapers --> bottled water with interest 66.975636\n",
      "25: bottled water --> bottled beer with interest 119.956364\n",
      "26: newspapers --> soda with interest 155.943273\n",
      "27: bottled beer --> soda with interest 155.943273\n",
      "28: newspapers --> bottled beer with interest 119.956364\n"
     ]
    }
   ],
   "source": [
    "L2_table5 = [ elem for elem in list(L2_table5) if len(elem)>1] # clean our list a bit. \n",
    "count=1\n",
    "for i in range(len(L2_table5)):\n",
    "\n",
    "    A, B = list(L2_table5[i])\n",
    "    support_AB = C2_table5[frozenset([A, B])]\n",
    "    support_A = C1[frozenset([A])]\n",
    "    conf_A_leads_to_B = support_AB / support_A\n",
    "    \n",
    "    support_B = C1[frozenset([B])]\n",
    "    prob_B = support_B / 2750.0\n",
    "    \n",
    "    interest_A_leads_to_B = conf_A_leads_to_B - prob_B\n",
    "    \n",
    "    if interest_A_leads_to_B > 0.7:\n",
    "        print(\"{}: {} --> {} with interest {:3f}\".format(count,A, B, interest_A_leads_to_B))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-times",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "illegal-staff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table 1:\n",
      "   time: 252.1904172897339 sec,\n",
      "   items 36\n",
      "table 2:\n",
      "   time: 422.3184566497803 sec,\n",
      "   items 36\n",
      "table 3:\n",
      "   time: 536.6535396575928 sec,\n",
      "   items 36\n",
      "table 4:\n",
      "   time: 600.8096449375153 sec,\n",
      "   items 36\n",
      "table 5:\n",
      "   time: 709.8312077522278 sec,\n",
      "   items 36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'table 1:\\n   time: {table1_time} sec,\\n   items {len(C2_table1)}')\n",
    "print(f'table 2:\\n   time: {table2_time} sec,\\n   items {len(C2_table2)}')\n",
    "print(f'table 3:\\n   time: {table3_time} sec,\\n   items {len(C2_table3)}')\n",
    "print(f'table 4:\\n   time: {table4_time} sec,\\n   items {len(C2_table4)}')\n",
    "print(f'table 5:\\n   time: {table5_time} sec,\\n   items {len(C2_table5)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-browser",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
